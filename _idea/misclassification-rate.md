---
layout: post
title: 关于模式识别中的最小错误率决策
tags: 模式识别系列
---

分类是模式识别中的基本问题，它通过分析数据的特征决定应被归入的类别。实际应用中的分类模型多种多样，但是它们的原理基本都是通过对特征进行聚类来判断其所属类别。比如将特征空间分为 *n* 个区域 $$R_1,R_2,,,R_n$$ ，并且这些区域互不重叠，也就是 $$R_i \cap R_j = \emptyset$$，对任意 $$i\ne j$$ 都成立。那么对于一个特征 *x* ， 只需要观察它所在的区域就能判断其所表示的类别，这里我们用 $$\mathcal{C}_1, \mathcal{C}_2,,,\mathcal{C}_n$$ 来表示种类。

一次分类行为应该区分清楚两个事件，其一是通过一定的方式计算出特征所在的区域，其二是特征本身所处的类别。第一个事件显然是我们做出判别的依据，它可以表示成 $$x \in R_i $$，而第二个则用类别的标识来表示即可 $$\mathbf{C}_j$$。显然，这两个事件都是随机的，我们可以将它们的概率表示出来，即

$$
p(x\in R_i)\,, \quad p(\mathcal{C}_j)
$$

其中 $$p(\mathcal{C}_j)$$ 是在不知道任何有关特征的信息下，类别 $$\mathcal{C}_j$$ 出现的概率，也被称为先验概率。它们的联合分布为

$$
p(x \in R_i, \mathcal{C}_j)
$$

如果在上述联合分布中，$$i = j$$，即 $$x\in R_i$$ 和 $$x$$ 本身属于类别 $$\mathcal{C}_i$$ ，也就是两个事件同时发生，就说明分类是正确的，否则就是错误的。于是一般来讲，对于某一个特征，若不具有任何先验知识，它被正确分类的概率显然就为

$$
p(correct) = \sum_{i=1}^n p(x\in R_i, \, \mathcal{C}_i)
$$

根据概率的互斥关系，它被错误分类的概率等于 1 减去正确率

$$
p(error) = 1 -p(correct)
$$

到这里，我们的任务就已经很明显了，那就是想尽办法提高分类正确率，或者减小错误率，显然在这一层面上，最好的决策使错误率最小，这就是基于最小错误率的决策方案。

为了计算正确率，考虑如下推导

$$
\begin{aligned}
p(correct) &= \sum_{i=1}^n p(x\in R_i, \, \mathcal{C}_i)\\
&=\sum_{i=1}^n \int_{x\in R_i}p(x, \mathcal{C}_i)\mathbf{d}x\\
&=\sum_{i=1}^n \int_{x\in R_i}p(\mathcal{C}_i\mid x)p(x)\mathbf{d}x
\end{aligned}
$$














end

end
